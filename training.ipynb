{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-petrov-git/phd-test/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "def unzip_trajectories(zip_path, output_dir=\"trajectories\"):\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Error: .zip file '{zip_path}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Unzipping '{zip_path}' to '{output_dir}'...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            temp_dir = \"temp_extract\"\n",
        "            zip_ref.extractall(temp_dir)\n",
        "\n",
        "            for root, _, files in os.walk(temp_dir):\n",
        "                for file in files:\n",
        "                    if file.endswith(\".pkl\"):\n",
        "                        src_path = os.path.join(root, file)\n",
        "                        dst_path = os.path.join(output_dir, file)\n",
        "                        shutil.move(src_path, dst_path)\n",
        "                        print(f\"Extracted '{file}' to '{output_dir}'\")\n",
        "                    else:\n",
        "                        print(f\"Skipping non-.pkl file: '{file}'\")\n",
        "\n",
        "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
        "\n",
        "        print(f\"Successfully unzipped '{zip_path}' to '{output_dir}'\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: '{zip_path}' is corrupted or not a valid .zip file\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error unzipping '{zip_path}': {e}\")"
      ],
      "metadata": {
        "id": "1XXXilYxXQzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path_1 = \"robot_trajectories_20250601_123205.zip\"\n",
        "unzip_trajectories(zip_path_1, output_dir=\"trajectories\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jxQNh_Wb5zT",
        "outputId": "4e71cccd-d20d-4cc5-8498-3d7cc8e176d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping 'robot_trajectories_20250601_123205.zip' to 'trajectories'...\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0006.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0021.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0018.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0008.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0019.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0001.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0015.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0007.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0003.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0017.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0004.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0014.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0009.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0005.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0013.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0002.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0012.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0010.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0020.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0016.pkl' to 'trajectories'\n",
            "Extracted 'google_robot_pick_coke_can_rt1_x_trajectory_0011.pkl' to 'trajectories'\n",
            "Successfully unzipped 'robot_trajectories_20250601_123205.zip' to 'trajectories'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_actions = []\n",
        "for file in os.listdir(\"trajectories\"):\n",
        "    if file.endswith(\".pkl\"):\n",
        "        with open(os.path.join(\"trajectories\", file), \"rb\") as f:\n",
        "            traj = pickle.load(f)\n",
        "            all_actions.extend(traj['actions'])\n",
        "all_actions = np.array(all_actions)\n",
        "print(\"Min/Max per action dim:\", all_actions.min(axis=0), all_actions.max(axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAHUPleIo3ob",
        "outputId": "f392279c-a7e9-4f01-fb95-6acf4fa2eaaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min/Max per action dim: [-0.01956952 -0.06653619 -0.07436395 -0.04610944 -0.3227663  -0.0768491\n",
            " -1.        ] [0.1291585  0.19178081 0.09001946 0.4149853  0.09529293 0.18136406\n",
            " 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. nanoGPT training"
      ],
      "metadata": {
        "id": "2PGwUc3h1--a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karpathy/nanoGPT.git\n",
        "!pip install torchvision\n",
        "!pip install transformers\n",
        "!pip install scikit-learn\n",
        "!pip install einops\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "SUz6FFLb2Okd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e534cd5-2ffb-450f-ba52-99219aaf7f31",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nanoGPT'...\n",
            "remote: Enumerating objects: 686, done.\u001b[K\n",
            "remote: Total 686 (delta 0), reused 0 (delta 0), pack-reused 686 (from 1)\u001b[K\n",
            "Receiving objects: 100% (686/686), 954.04 KiB | 2.99 MiB/s, done.\n",
            "Resolving deltas: 100% (387/387), done.\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer\n",
        "from torchvision.models import resnet18\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "import sys\n",
        "sys.path.append('./nanoGPT')\n",
        "from model import GPT, GPTConfig"
      ],
      "metadata": {
        "id": "GcSXNM7s_PcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RoboDataset(Dataset):\n",
        "    def __init__(self, trajectory_dir, text_tokenizer, max_seq_len=256, bins_per_dim=64):\n",
        "        self.tokenizer = text_tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.bins_per_dim = bins_per_dim\n",
        "        self.data = []\n",
        "        self.embedding_dim = 768\n",
        "        self.image_encoder = resnet18(pretrained=True)\n",
        "        self.image_encoder.fc = nn.Linear(512, self.embedding_dim)\n",
        "        self.image_encoder.eval()\n",
        "\n",
        "        trajectory_files = [os.path.join(trajectory_dir, f) for f in os.listdir(trajectory_dir) if f.endswith(\".pkl\")]\n",
        "        for file in trajectory_files:\n",
        "            with open(file, 'rb') as f:\n",
        "                traj = pickle.load(f)\n",
        "                instruction_tokens = self.tokenizer.encode(traj['instructions'], add_special_tokens=True)\n",
        "                for i in range(len(traj['images'])):\n",
        "                    self.data.append({\n",
        "                        'image': traj['images'][i],\n",
        "                        'action': traj['actions'][i],\n",
        "                        'instruction_tokens': instruction_tokens\n",
        "                    })\n",
        "\n",
        "        self._compute_action_ranges()\n",
        "\n",
        "    def discretize_action(self, action):\n",
        "        action = np.clip(action, self.action_mins, self.action_maxs)\n",
        "        action_normalized = (action - self.action_mins) / (self.action_maxs - self.action_mins)\n",
        "        action_tokens = np.floor(action_normalized * self.bins_per_dim).astype(int)\n",
        "        return np.clip(action_tokens, 0, self.bins_per_dim - 1)\n",
        "\n",
        "    def undiscretize_action(self, action_tokens):\n",
        "        action_continuous = (action_tokens + 0.5) / self.bins_per_dim\n",
        "        return self.action_mins + action_continuous * (self.action_maxs - self.action_mins)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        img = torch.tensor(item['image'], dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
        "        with torch.no_grad():\n",
        "            img_embedding = self.image_encoder(img.unsqueeze(0)).squeeze(0)\n",
        "\n",
        "        instruction_tokens = torch.tensor(item['instruction_tokens'], dtype=torch.long)\n",
        "\n",
        "        action_tokens = self.discretize_action(item['action'])\n",
        "        # print(f\"Action token range: {np.min(action_tokens)}-{np.max(action_tokens)}\")  # Should be 0-63\n",
        "\n",
        "        action_tokens = torch.tensor(action_tokens, dtype=torch.long)\n",
        "        return instruction_tokens, img_embedding, action_tokens\n",
        "\n",
        "    def _compute_action_ranges(self):\n",
        "        all_actions = np.array([item['action'] for item in self.data])\n",
        "        self.action_mins = all_actions.min(axis=0)\n",
        "        self.action_maxs = all_actions.max(axis=0)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    instructions, img_embeddings, action_tokens = zip(*batch)\n",
        "    instructions_padded = torch.nn.utils.rnn.pad_sequence(instructions, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    img_embeddings_stacked = torch.stack(img_embeddings)\n",
        "    action_tokens_stacked = torch.stack(action_tokens)\n",
        "    return instructions_padded, img_embeddings_stacked, action_tokens_stacked"
      ],
      "metadata": {
        "id": "MC10SUkQ9CTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RoboGPT(GPT):\n",
        "    def __init__(self, config, action_dim=7, bins_per_dim=64):\n",
        "        super().__init__(config)\n",
        "        self.action_dim = action_dim\n",
        "        self.bins_per_dim = bins_per_dim\n",
        "        self.img_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.cross_attn = nn.MultiheadAttention(config.n_embd, num_heads=4)\n",
        "\n",
        "        self.action_heads = nn.ModuleList([nn.Linear(config.n_embd, bins_per_dim) for _ in range(action_dim)])\n",
        "\n",
        "    def forward(self, instruction_tokens, img_embeddings=None, targets=None):\n",
        "        device = instruction_tokens.device\n",
        "        b, t = instruction_tokens.size()\n",
        "\n",
        "        tok_emb = self.transformer.wte(instruction_tokens)\n",
        "        pos_emb = self.transformer.wpe(torch.arange(0, t, device=device))\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "\n",
        "        if img_embeddings is not None:\n",
        "            img_emb = self.img_proj(img_embeddings).unsqueeze(0)\n",
        "            x, _ = self.cross_attn(x.transpose(0, 1), img_emb, img_emb)\n",
        "            x = x.transpose(0, 1)\n",
        "\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        last_emb = x[:, -1, :]\n",
        "        logits = [head(last_emb) for head in self.action_heads]\n",
        "        logits = torch.stack(logits, dim=1)\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            # print(f\"Target min/max: {torch.min(targets)}/{torch.max(targets)}\")  # Should be 0-63\n",
        "            loss = sum(F.cross_entropy(logits[:, i, :], targets[:, i]) for i in range(self.action_dim))\n",
        "        return logits, loss"
      ],
      "metadata": {
        "id": "y0UvK8FM9JG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RoboBatchHandler:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        action_mins,\n",
        "        action_maxs,\n",
        "        optimizer=None,\n",
        "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "        bins_per_dim=64\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.bins_per_dim = bins_per_dim\n",
        "        self.action_mins = action_mins\n",
        "        self.action_maxs = action_maxs\n",
        "\n",
        "    def undiscretize_action(self, action_tokens):\n",
        "        action_continuous = (action_tokens + 0.5) / self.bins_per_dim\n",
        "        return self.action_mins + action_continuous * (self.action_maxs - self.action_mins)\n",
        "\n",
        "    def handle_batch(self, is_train, batch):\n",
        "        \"\"\"Process a single batch, returns dict of metrics\"\"\"\n",
        "        instruction_tokens, img_embeddings, action_tokens = batch\n",
        "        instruction_tokens = instruction_tokens.to(self.device)\n",
        "        img_embeddings = img_embeddings.to(self.device)\n",
        "        action_tokens = action_tokens.to(self.device)\n",
        "\n",
        "        logits, loss = self.model(instruction_tokens, img_embeddings, action_tokens)\n",
        "\n",
        "        if is_train:\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_tokens = logits.argmax(-1).cpu().numpy()\n",
        "            gt_tokens = action_tokens.cpu().numpy()\n",
        "            pred_actions = self.undiscretize_action(pred_tokens)\n",
        "            gt_actions = self.undiscretize_action(gt_tokens)\n",
        "            mse = np.mean((pred_actions - gt_actions) ** 2)\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss.item(),\n",
        "            \"action_mse\": mse,\n",
        "            \"batch_size\": instruction_tokens.size(0)\n",
        "        }\n",
        "\n",
        "def train_epoch(dataloader, handler):\n",
        "    handler.model.train()\n",
        "    epoch_metrics = {\"loss\": 0, \"action_mse\": 0}\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        metrics = handler.handle_batch(is_train=True, batch=batch)\n",
        "        for k in epoch_metrics:\n",
        "            epoch_metrics[k] += metrics[k] * metrics[\"batch_size\"]\n",
        "\n",
        "    for k in epoch_metrics:\n",
        "        epoch_metrics[k] /= len(dataloader.dataset)\n",
        "    return epoch_metrics\n",
        "\n",
        "def test_epoch(dataloader, handler):\n",
        "    handler.model.eval()\n",
        "    epoch_metrics = {\"loss\": 0, \"action_mse\": 0}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Validation\"):\n",
        "            metrics = handler.handle_batch(is_train=False, batch=batch)\n",
        "            for k in epoch_metrics:\n",
        "                epoch_metrics[k] += metrics[k] * metrics[\"batch_size\"]\n",
        "\n",
        "    for k in epoch_metrics:\n",
        "        epoch_metrics[k] /= len(dataloader.dataset)\n",
        "    return epoch_metrics\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    dataset,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    num_epochs=20,\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    project_name=\"robot-nanogpt-imitation\"\n",
        "):\n",
        "    wandb.init(project=project_name)\n",
        "    wandb.watch(model)\n",
        "\n",
        "    handler = RoboBatchHandler(\n",
        "        model=model,\n",
        "        action_mins=dataset.action_mins,\n",
        "        action_maxs=dataset.action_maxs,\n",
        "        optimizer=optimizer,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    best_val_mse = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        train_metrics = train_epoch(train_loader, handler)\n",
        "\n",
        "        # Validation phase\n",
        "        val_metrics = test_epoch(val_loader, handler)\n",
        "\n",
        "        # Log metrics\n",
        "        log_dict = {\n",
        "            \"epoch\": epoch,\n",
        "            \"train/loss\": train_metrics[\"loss\"],\n",
        "            \"train/action_mse\": train_metrics[\"action_mse\"],\n",
        "            \"val/loss\": val_metrics[\"loss\"],\n",
        "            \"val/action_mse\": val_metrics[\"action_mse\"]\n",
        "        }\n",
        "        wandb.log(log_dict)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"  Train Loss: {train_metrics['loss']:.4f} | Train MSE: {train_metrics['action_mse']:.4f}\")\n",
        "        print(f\"  Val Loss: {val_metrics['loss']:.4f} | Val MSE: {val_metrics['action_mse']:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_metrics[\"action_mse\"] < best_val_mse:\n",
        "            best_val_mse = val_metrics[\"action_mse\"]\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(\"  Saved new best model!\")\n",
        "\n",
        "    wandb.finish()\n",
        "    return model"
      ],
      "metadata": {
        "id": "QR6la1UFyrrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "dataset = RoboDataset(\"trajectories\", tokenizer, bins_per_dim=64)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset)-train_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)\n",
        "\n",
        "config = GPTConfig(block_size=256, vocab_size=len(tokenizer), n_layer=6, n_head=6, n_embd=768)\n",
        "model = RoboGPT(config, action_dim=7, bins_per_dim=64).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "bScDQppwywi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0cd71eb-6a8c-46ab-82cf-eb29fd704a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 81.13M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train(\n",
        "    model=model,\n",
        "    dataset=dataset,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=20\n",
        ")"
      ],
      "metadata": {
        "id": "HyIFgpG9y0G3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b3c76ea-a4f3-4b83-c0d4-bfc456e4b89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rare-snowflake-2</strong> at: <a href='https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation/runs/muu8uj5t' target=\"_blank\">https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation/runs/muu8uj5t</a><br> View project at: <a href='https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation' target=\"_blank\">https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250601_134835-muu8uj5t/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250601_140109-re9d7iqq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation/runs/re9d7iqq' target=\"_blank\">dazzling-grass-3</a></strong> to <a href='https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation' target=\"_blank\">https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation/runs/re9d7iqq' target=\"_blank\">https://wandb.ai/alex-petrovortex-mipt/robot-nanogpt-imitation/runs/re9d7iqq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:45<00:00,  5.01s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:32<00:00,  4.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "  Train Loss: 11.2110 | Train MSE: 0.0106\n",
            "  Val Loss: 10.7975 | Val MSE: 0.0124\n",
            "  Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:47<00:00,  5.05s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:30<00:00,  4.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20\n",
            "  Train Loss: 9.8666 | Train MSE: 0.0102\n",
            "  Val Loss: 10.5272 | Val MSE: 0.0124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:48<00:00,  5.06s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:32<00:00,  4.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20\n",
            "  Train Loss: 9.6257 | Train MSE: 0.0102\n",
            "  Val Loss: 10.0505 | Val MSE: 0.0120\n",
            "  Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:44<00:00,  4.98s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:31<00:00,  4.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20\n",
            "  Train Loss: 8.9953 | Train MSE: 0.0100\n",
            "  Val Loss: 10.0956 | Val MSE: 0.0121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:41<00:00,  4.94s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:31<00:00,  4.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20\n",
            "  Train Loss: 8.1621 | Train MSE: 0.0099\n",
            "  Val Loss: 8.5414 | Val MSE: 0.0112\n",
            "  Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:46<00:00,  5.03s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:31<00:00,  4.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20\n",
            "  Train Loss: 7.5564 | Train MSE: 0.0097\n",
            "  Val Loss: 8.3129 | Val MSE: 0.0114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:45<00:00,  5.01s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:31<00:00,  4.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20\n",
            "  Train Loss: 7.0747 | Train MSE: 0.0092\n",
            "  Val Loss: 8.3368 | Val MSE: 0.0100\n",
            "  Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:41<00:00,  4.93s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:31<00:00,  4.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20\n",
            "  Train Loss: 6.7094 | Train MSE: 0.0091\n",
            "  Val Loss: 7.2759 | Val MSE: 0.0107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:43<00:00,  4.98s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:31<00:00,  4.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20\n",
            "  Train Loss: 6.5485 | Train MSE: 0.0103\n",
            "  Val Loss: 8.3085 | Val MSE: 0.0109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:45<00:00,  5.00s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:32<00:00,  4.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20\n",
            "  Train Loss: 6.3040 | Train MSE: 0.0088\n",
            "  Val Loss: 7.1241 | Val MSE: 0.0090\n",
            "  Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:52<00:00,  5.13s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:31<00:00,  4.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20\n",
            "  Train Loss: 5.9238 | Train MSE: 0.0095\n",
            "  Val Loss: 6.8113 | Val MSE: 0.0106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:47<00:00,  5.04s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:32<00:00,  4.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20\n",
            "  Train Loss: 6.0188 | Train MSE: 0.0091\n",
            "  Val Loss: 7.0763 | Val MSE: 0.0097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 57/57 [04:45<00:00,  5.01s/it]\n",
            "Validation: 100%|██████████| 7/7 [00:31<00:00,  4.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20\n",
            "  Train Loss: 5.8552 | Train MSE: 0.0088\n",
            "  Val Loss: 6.4602 | Val MSE: 0.0107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  65%|██████▍   | 37/57 [03:06<01:40,  5.04s/it]"
          ]
        }
      ]
    }
  ]
}